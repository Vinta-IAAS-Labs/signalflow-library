from signalfx.detectors.autodetect import utils
from signalfx.detectors.autodetect.infra.azure import utils as azure_utils
from signalfx.detectors.against_recent import against_recent

def task_fail_event_detector(fire_threshold: float = 0, 
                                 fire_lasting: lasting = lasting('20m', 0.8),
                                 clear_threshold: float = 0,
                                 clear_lasting: lasting = lasting('20m', 0.8),
                                 filter_: filter = None):
    # Detects when failed task event count is above threshold
    # :param fire_threshold description=Specifies trigger threshold for the failed task event
    # :param fire_threshold label=Trigger threshold
    # :param fire_lasting description=Specifies trigger sensitivity associated with trigger threshold
    # :param fire_lasting label=Trigger sensitivity
    # :param clear_threshold description=Specifies clear threshold for the failed task event
    # :param clear_threshold label=Clear threshold
    # :param clear_threshold constraint=lte(fire_threshold)
    # :param clear_lasting description=Specifies clear sensitivity associated with clear threshold
    # :param clear_lasting label=Clear sensitivity
    # :param filter_ description=Specifies dimensional scope of the detector
    # :param filter_ metric_name=TaskFailEvent
    # :return: detect block that triggers when failed task count is above the threshold
    
    assert fire_threshold >= clear_threshold, utils.threshold_validation_err_msg(fire_threshold, clear_threshold,
                                                                                 orientation='above')
    initial_filter = filter(azure_utils.RESOURCE_TYPE, azure_utils.AZURE_BATCH) and filter(azure_utils.PRIMARY_AGGREGATION_TYPE, "true")
    scope_filter = utils.merge_filters(initial_filter, filter_)
    stream = data('TaskFailEvent', filter=scope_filter, extrapolation='zero').sum(by=azure_utils.AZURE_GROUP_BY).publish('Task failed event')
    
    

    fire_threshold_stream = const(fire_threshold)
    clear_threshold_stream = const(clear_threshold)

    ann = [utils.annotate_stream(stream, 'Task failed event'),
           utils.annotate_fire_threshold(fire_threshold_stream, orientation='above')]

    return detect(when(stream > fire_threshold_stream, lasting = fire_lasting),
                  off=when(stream <= clear_threshold_stream, lasting = clear_lasting),
                  annotations=ann,
                  auto_resolve_after=utils.AUTO_RESOLVE_AFTER)

def start_task_failed_node_detector(fire_threshold: float = 0, 
                                    fire_lasting: lasting = lasting('20m', 0.8),
                                    clear_threshold: float = 0,
                                    clear_lasting: lasting = lasting('20m', 0.8),
                                    filter_: filter = None):
    # Detects when start task failed node count are above threshold
    # :param fire_threshold description=Specifies trigger threshold for the failed node count
    # :param fire_threshold label=Trigger threshold
    # :param fire_lasting description=Specifies trigger sensitivity associated with trigger threshold
    # :param fire_lasting label=Trigger sensitivity
    # :param clear_threshold description=Specifies clear threshold for the failed node count
    # :param clear_threshold label=Clear threshold
    # :param clear_threshold constraint=lte(fire_threshold)
    # :param clear_lasting description=Specifies clear sensitivity associated with clear threshold
    # :param clear_lasting label=Clear sensitivity
    # :param filter_ description=Specifies dimensional scope of the detector
    # :param filter_ metric_name=StartTaskFailedNodeCount
    # :return: detect block that triggers when start task failed node count is above the threshold
    
    assert fire_threshold >= clear_threshold, utils.threshold_validation_err_msg(fire_threshold, clear_threshold,
                                                                                 orientation='above')
    initial_filter = filter(azure_utils.RESOURCE_TYPE, azure_utils.AZURE_BATCH) and filter(azure_utils.PRIMARY_AGGREGATION_TYPE, "true")
    scope_filter = utils.merge_filters(initial_filter, filter_)
    stream = data('StartTaskFailedNodeCount', filter=scope_filter).sum(by=azure_utils.AZURE_GROUP_BY)
    
    
    fire_threshold_stream = const(fire_threshold)
    clear_threshold_stream = const(clear_threshold)

    ann = [utils.annotate_stream(stream, 'Start task failed node'),
           utils.annotate_fire_threshold(fire_threshold_stream, orientation='above')]

    return detect(when(stream > fire_threshold_stream, lasting = fire_lasting),
                  off=when(stream <= clear_threshold_stream, lasting = clear_lasting),
                  annotations=ann,
                  auto_resolve_after=utils.AUTO_RESOLVE_AFTER)


def running_node_detector(fire_num_stddev: float = 3.5,
                         current_window: duration = duration('20m'),
                         historical_window: duration = duration('1h'),
                         filter_: filter = None):
    # :param fire_num_stddev label=Trigger deviation
    # :param fire_num_stddev description=Expressed in standard deviations from baseline
    # :param fire_num_stddev min=0
    # :param fire_num_stddev step=0.1
    # :param fire_num_stddev unit=SD
    # :param current_window description=The time range being monitored
    # :param current_window label=Evaluation window
    # :param historical_window description=The time range being used to define the recent trend
    # :param historical_window label=Historical window
    # :param filter_ description=Specifies dimensional scope of the detector
    # :param filter_ metric_name=RunningNodeCount
    # :return: detect block that triggers when number of running nodes suddenly increased
    
    initial_filter = filter(azure_utils.RESOURCE_TYPE, azure_utils.AZURE_BATCH) and filter(azure_utils.PRIMARY_AGGREGATION_TYPE, "true")
    scope_filter = utils.merge_filters(initial_filter, filter_)
    stream = data('RunningNodeCount', filter=scope_filter).sum(by=azure_utils.AZURE_GROUP_BY).publish(label='Running nodes')
    clear_num_stddev = max(fire_num_stddev - 0.5, 0)
    return against_recent.detector_mean_std(stream=stream,
                                            current_window=current_window,
                                            historical_window=historical_window,
                                            fire_num_stddev=fire_num_stddev,
                                            clear_num_stddev=clear_num_stddev,
                                            orientation='above',
                                            ignore_extremes=True,
                                            calculation_mode='vanilla',
                                            auto_resolve_after=utils.AUTO_RESOLVE_AFTER)

def task_start_event_detector(fire_num_stddev: float = 3.5,
                         current_window: duration = duration('20m'),
                         historical_window: duration = duration('1h'),
                         filter_: filter = None):
    # :param fire_num_stddev label=Trigger deviation
    # :param fire_num_stddev description=Expressed in standard deviations from baseline
    # :param fire_num_stddev min=0
    # :param fire_num_stddev step=0.1
    # :param fire_num_stddev unit=SD
    # :param current_window description=The time range being monitored
    # :param current_window label=Evaluation window
    # :param historical_window description=The time range being used to define the recent trend
    # :param historical_window label=Historical window
    # :param filter_ description=Specifies dimensional scope of the detector
    # :param filter_ metric_name=TaskStartEvent
    # :return: detect block that triggers when number of task start event suddenly decreased
    
    initial_filter = filter(azure_utils.RESOURCE_TYPE, azure_utils.AZURE_BATCH) and filter(azure_utils.PRIMARY_AGGREGATION_TYPE, "true")
    scope_filter = utils.merge_filters(initial_filter, filter_)
    stream = data('TaskStartEvent', filter=scope_filter).sum(by=azure_utils.AZURE_GROUP_BY).publish(label='Task start event')
    clear_num_stddev = max(fire_num_stddev - 0.5, 0)
    return against_recent.detector_mean_std(stream=stream,
                                            current_window=current_window,
                                            historical_window=historical_window,
                                            fire_num_stddev=fire_num_stddev,
                                            clear_num_stddev=clear_num_stddev,
                                            orientation='below',
                                            ignore_extremes=True,
                                            calculation_mode='vanilla',
                                            auto_resolve_after=utils.AUTO_RESOLVE_AFTER)
